<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 5 - NLP Course DMGK</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #8B0000;
        }
        .notebook-link {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }
        .notebook-title {
            font-weight: 500;
            min-width: 300px;
        }
        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 1000;
        }
        .citation {
            margin-top: 10px;
            padding-left: 20px;
            border-left: 3px solid #8B0000;
        }
        .task {
            margin-bottom: 15px;
        }
    </style>
</head>
<body>
    <a href="../index.html" class="btn btn-secondary back-button">&larr; Go Back</a>

    <div class="container">
        <h1>Module 5: Large Language Models for Article Extraction and Post-OCR Correction</h1>
        
        <p>Module 5 will be all about large language models, prompting techniques and two specific NLP tasks: article extraction and OCR post-correction</p>
        <p>
            Large Language Models (LLMs) are artificial intelligence systems trained on massive text datasets that can process and generate human language based on the Transformer architecture introduced by Vaswear et al. in 2017. These models use neural networks to predict likely next tokens in a sequence, enabling tasks like text completion, translation, and question answering. While research shows correlations between model size, training data, and performance, specific capabilities and limitations continue to be actively studied and debated in the research community. They fundamentally operate through pattern matching rather than genuine understanding.
        </p>
        
        <h3>Preparation for Module 5:</h3>
        <ol>
            <li>Watch (if not done already) this YouTube Video on LLMs: <a href="https://www.youtube.com/watch?v=LPZh9BOjkQs&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=5">3Blue1Brown: Large Language Models</a></li>
            <li>Please read the blog post by Maraike König (referenced in the Literature section) and analyze the ethical implications of using LLMs. How do you incorporate data ethics in your LLM usage?</li>
            <li>Create an NVIDIA token:
                <ol>
                    <li>Visit the <a href="https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct">NVIDIA AI Playground</a></li>
                    <li>Click on login on the right top of the page</li>
                    <li>Enter your University Email</li>
                    <li>Copy the token</li>
                </ol>
            </li>
        </ol>

        <h3>Literature:</h3> 
        <p class="citation">
            Sahoo, P., Singh, A. K., Saha, S., Jain, V., Mondal, S., & Chadha, A. A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications. arXiv:2402.07927 (2024). 
            <a href="https://doi.org/10.48550/arXiv.2402.07927" target="_blank">https://doi.org/10.48550/arXiv.2402.07927</a>
        </p> 

        <p class="citation">
            Mareike König (19. August 2024). ChatGPT und Co. in den Geschichtswissenschaften – Grundlagen, Prompts und Praxisbeispiele. Digital Humanities am DHIP. Abgerufen am 2. Dezember 2024 von 
            <a href="https://doi.org/10.58079/126eo" target="_blank">https://doi.org/10.58079/126eo</a>
        </p> 
        
        <h3>Notebooks we will use in class:</h3>
        <div class="notebook-links">
            <div class="notebook-link">
                <span class="notebook-title">Prompting Techniques LLMs</span>
                <a href="https://colab.research.google.com/github/ieg-dhr/NLP-Course4Humanities_2024/blob/main/Prompting_Techniques_LLMs.ipynb" target="_blank">
                    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Prompting_Techniques_LLMs.ipynb In Colab"/>
                </a>
            </div>

            <div class="notebook-link">
                <span class="notebook-title">Large Language Models and Article Separation/OCR Post-Correction</span>
                <a href="https://colab.research.google.com/github/ieg-dhr/NLP-Course4Humanities_2024/blob/main/Large_Language_Models_Article_Separation.ipynb" target="_blank">
                    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Large_Language_Models_Article_Separation.ipynb In Colab"/>
                </a>
            </div>
        </div>

        <h3>Workload (after class):</h3>
        <p>Write a prompt for OCR Post-Correction and try it out in the Notebook "Large Language Models and Article Separation/OCR Post-Correction"</p>
        
        <h3>Date and Time:</h3>
        <p>December 6, 2024 (10:00 AM to 11:30 AM)</p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
